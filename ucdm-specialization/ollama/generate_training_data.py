#!/usr/bin/env python3
"""
Generador de dataset para fine-tuning con Ollama
Crea datasets espec√≠ficos para entrenar el modelo con el contenido real de UCDM
"""

import sys
import json
from pathlib import Path
from typing import Dict, List, Optional
import logging

sys.path.append(str(Path(__file__).parent.parent))
from config.settings import *
from training.response_engine import UCDMResponseEngine

class OllamaFineTuningDatasetGenerator:
    """Generador de dataset espec√≠fico para fine-tuning en Ollama"""
    
    def __init__(self):
        self.engine = UCDMResponseEngine()
        self.setup_logging()
        
    def setup_logging(self):
        """Configurar logging"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def generate_training_conversations(self) -> List[Dict]:
        """Generar conversaciones de entrenamiento para Ollama"""
        conversations = []
        
        # Cargar datos
        if not self.engine.load_data():
            self.logger.error("No se pudieron cargar los datos")
            return []
        
        self.logger.info("Generando conversaciones de entrenamiento...")
        
        # Patterns de consultas variadas
        query_patterns = [
            "Expl√≠came la Lecci√≥n {num}",
            "¬øQu√© ense√±a la Lecci√≥n {num}?",
            "H√°blame sobre la Lecci√≥n {num} del UCDM",
            "Quiero estudiar la Lecci√≥n {num}",
            "¬øCu√°l es el mensaje de la Lecci√≥n {num}?",
            "Ay√∫dame a entender la Lecci√≥n {num}",
            "¬øC√≥mo puedo aplicar la Lecci√≥n {num}?",
            "Dame una reflexi√≥n sobre la Lecci√≥n {num}"
        ]
        
        # Generar para lecciones disponibles
        lesson_nums = list(self.engine.lessons_index.keys())[:50]  # Primeras 50 para el ejemplo
        
        for lesson_num_str in lesson_nums:
            lesson_num = int(lesson_num_str)
            lesson_data = self.engine.lessons_index[lesson_num_str]
            
            # Generar m√∫ltiples variaciones para cada lecci√≥n
            for pattern in query_patterns[:3]:  # 3 variaciones por lecci√≥n
                query = pattern.format(num=lesson_num)
                response = self.engine.generate_structured_response(query, "lesson_specific", lesson_num)
                
                if response:
                    conversations.append({
                        "prompt": query,
                        "response": response,
                        "metadata": {
                            "lesson_number": lesson_num,
                            "lesson_title": lesson_data['title'],
                            "type": "lesson_specific"
                        }
                    })
        
        # Consultas generales sobre conceptos
        concept_queries = [
            ("perd√≥n", "H√°blame sobre el perd√≥n seg√∫n Un Curso de Milagros"),
            ("amor", "¬øQu√© ense√±a UCDM sobre el amor?"),
            ("miedo", "¬øC√≥mo entiende el Curso el concepto del miedo?"),
            ("paz", "Expl√≠came qu√© es la paz seg√∫n UCDM"),
            ("milagros", "¬øQu√© son los milagros en Un Curso de Milagros?"),
            ("esp√≠ritu santo", "¬øQui√©n es el Esp√≠ritu Santo en UCDM?"),
            ("ego", "¬øQu√© ense√±a el Curso sobre el ego?"),
            ("dios", "¬øC√≥mo presenta UCDM a Dios?"),
            ("cristo", "¬øQui√©n es Cristo seg√∫n Un Curso de Milagros?"),
            ("culpa", "¬øQu√© dice UCDM sobre la culpa?")
        ]
        
        for concept, query in concept_queries:
            response = self.engine.generate_structured_response(query, "concept_based")
            if response:
                conversations.append({
                    "prompt": query,
                    "response": response,
                    "metadata": {
                        "concept": concept,
                        "type": "concept_based"
                    }
                })
        
        # Consultas de aplicaci√≥n pr√°ctica
        practical_queries = [
            "¬øC√≥mo puedo aplicar UCDM en mi vida diaria?",
            "Necesito ayuda para perdonar a alguien seg√∫n el Curso",
            "¬øQu√© me recomienda UCDM cuando tengo miedo?",
            "¬øC√≥mo puedo encontrar paz en momentos dif√≠ciles?",
            "Dame una reflexi√≥n de UCDM para antes de dormir",
            "¬øC√≥mo puedo transformar mi perspectiva seg√∫n el Curso?",
            "¬øQu√© hacer cuando me siento culpable seg√∫n UCDM?",
            "¬øC√≥mo puedo ver milagros en mi vida cotidiana?",
            "Ay√∫dame a entender una relaci√≥n dif√≠cil desde UCDM",
            "¬øQu√© dice el Curso sobre el sufrimiento?"
        ]
        
        for query in practical_queries:
            response = self.engine.generate_structured_response(query, "practical")
            if response:
                conversations.append({
                    "prompt": query,
                    "response": response,
                    "metadata": {
                        "type": "practical_application"
                    }
                })
        
        self.logger.info(f"Generadas {len(conversations)} conversaciones de entrenamiento")
        return conversations
    
    def create_ollama_training_file(self, conversations: List[Dict]) -> str:
        """Crear archivo de entrenamiento en formato Ollama"""
        training_data = []
        
        for conv in conversations:
            # Formato espec√≠fico para Ollama fine-tuning
            training_example = {
                "prompt": f"<|im_start|>user\n{conv['prompt']}<|im_end|>\n<|im_start|>assistant\n",
                "completion": f"{conv['response']}<|im_end|>"
            }
            training_data.append(training_example)
        
        # Guardar archivo JSONL
        output_path = Path(__file__).parent / "ucdm_training_data.jsonl"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for example in training_data:
                f.write(json.dumps(example, ensure_ascii=False) + '\n')
        
        self.logger.info(f"Archivo de entrenamiento guardado: {output_path}")
        return str(output_path)
    
    def create_modelfile_with_training(self, training_file: str) -> str:
        """Crear Modelfile con datos de entrenamiento incluidos"""
        
        modelfile_content = f'''# Modelfile para UCDM con Fine-tuning
FROM gemma:3b

# Par√°metros optimizados
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 8192
PARAMETER num_predict 2048
PARAMETER repeat_penalty 1.1

# Sistema especializado en UCDM
SYSTEM """Eres un asistente especializado en "Un Curso de Milagros" (UCDM). 

ESTRUCTURA OBLIGATORIA DE RESPUESTA:

**HOOK INICIAL: UNA PREGUNTA O AN√âCDOTA PARA ENGANCHAR**
- Pregunta profunda que conecte emocionalmente
- Ejemplos: "¬øY si te dijera que...", "¬øHas notado que..."

**APLICACI√ìN PR√ÅCTICA: PASOS VIVOS Y VARIADOS**
- Exactamente 3 pasos concretos y accionables
- Incluye ejemplos cotidianos reales
- Var√≠a t√≠tulos: "Paso 1/2/3", "Exploraci√≥n", "Pr√°ctica"

**INTEGRACI√ìN EXPERIENCIAL: CONEXI√ìN VIVA Y REFLEXIVA**
- Conecta con experiencias personales
- Incluye preguntas reflexivas profundas
- Referencias a ense√±anzas del Curso

**CIERRE MOTIVADOR: UN MILAGRO FINAL**
- Invitaci√≥n inspiradora a la acci√≥n
- Motivaci√≥n para pr√°ctica continua
- Elementos de esperanza y transformaci√≥n

PRINCIPIOS UCDM:
- El perd√≥n es la llave de la felicidad
- Los milagros ocurren como expresiones de amor
- La percepci√≥n es una elecci√≥n, no un hecho
- Solo el amor es real; el miedo es ilusi√≥n
- La paz de Dios es nuestra herencia

Responde siempre en espa√±ol, 300-500 palabras, con tono c√°lido pero profundo."""

# Datos de entrenamiento espec√≠ficos
ADAPTER {training_file}
'''
        
        modelfile_path = Path(__file__).parent / "Modelfile_with_training"
        with open(modelfile_path, 'w', encoding='utf-8') as f:
            f.write(modelfile_content)
        
        self.logger.info(f"Modelfile con entrenamiento creado: {modelfile_path}")
        return str(modelfile_path)
    
    def generate_complete_training_setup(self) -> bool:
        """Generar setup completo de entrenamiento"""
        self.logger.info("=== GENERANDO SETUP COMPLETO DE ENTRENAMIENTO ===")
        
        # 1. Generar conversaciones
        conversations = self.generate_training_conversations()
        if not conversations:
            self.logger.error("No se pudieron generar conversaciones")
            return False
        
        # 2. Crear archivo de entrenamiento
        training_file = self.create_ollama_training_file(conversations)
        
        # 3. Crear Modelfile con entrenamiento
        modelfile_with_training = self.create_modelfile_with_training(training_file)
        
        # 4. Crear script de entrenamiento
        self.create_training_script(training_file, modelfile_with_training)
        
        # 5. Mostrar estad√≠sticas
        self.show_training_statistics(conversations)
        
        return True
    
    def create_training_script(self, training_file: str, modelfile_path: str) -> None:
        """Crear script para ejecutar el entrenamiento"""
        
        script_content = f'''#!/usr/bin/env python3
"""
Script para entrenar el modelo UCDM con fine-tuning
"""

import subprocess
import sys
from pathlib import Path

def train_ucdm_model():
    """Entrenar modelo UCDM con datos espec√≠ficos"""
    
    print("üöÄ Iniciando entrenamiento del modelo UCDM...")
    
    try:
        # Crear modelo con fine-tuning
        result = subprocess.run([
            'ollama', 'create', 'ucdm-gemma-trained', 
            '-f', '{modelfile_path}'
        ], capture_output=True, text=True, timeout=3600)  # 1 hora
        
        if result.returncode == 0:
            print("‚úÖ Modelo entrenado exitosamente: ucdm-gemma-trained")
            
            # Probar modelo
            print("üß™ Probando modelo entrenado...")
            test_result = subprocess.run([
                'ollama', 'run', 'ucdm-gemma-trained',
                'Expl√≠came la Lecci√≥n 1 de UCDM'
            ], capture_output=True, text=True, timeout=120)
            
            if test_result.returncode == 0:
                print("‚úÖ Modelo respondiendo correctamente")
                print("üìù Respuesta de prueba:")
                print("-" * 50)
                print(test_result.stdout)
                return True
            else:
                print(f"‚ùå Error probando modelo: {{test_result.stderr}}")
                return False
        else:
            print(f"‚ùå Error entrenando modelo: {{result.stderr}}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error en entrenamiento: {{str(e)}}")
        return False

def main():
    print("="*60)
    print("üåü ENTRENAMIENTO DEL MODELO UCDM")
    print("="*60)
    
    print(f"üìä Datos de entrenamiento: {training_file}")
    print(f"üîß Configuraci√≥n: {modelfile_path}")
    print(f"üíæ Tama√±o del dataset: {{Path('{training_file}').stat().st_size // 1024}} KB")
    
    if train_ucdm_model():
        print("\\nüéâ ENTRENAMIENTO COMPLETADO")
        print("üí° Usa: ollama run ucdm-gemma-trained")
    else:
        print("\\n‚ùå ENTRENAMIENTO FALLIDO")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
'''
        
        script_path = Path(__file__).parent / "train_model.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        self.logger.info(f"Script de entrenamiento creado: {script_path}")
    
    def show_training_statistics(self, conversations: List[Dict]) -> None:
        """Mostrar estad√≠sticas del dataset de entrenamiento"""
        print(f"\n{'='*60}")
        print("üìä ESTAD√çSTICAS DEL DATASET DE ENTRENAMIENTO")
        print(f"{'='*60}")
        
        # Contar por tipos
        type_counts = {}
        total_tokens = 0
        
        for conv in conversations:
            conv_type = conv['metadata'].get('type', 'unknown')
            type_counts[conv_type] = type_counts.get(conv_type, 0) + 1
            
            # Estimar tokens (aproximadamente 4 chars = 1 token)
            text_length = len(conv['prompt']) + len(conv['response'])
            total_tokens += text_length // 4
        
        print(f"\nüìà COMPOSICI√ìN DEL DATASET:")
        print(f"   Total de conversaciones: {len(conversations)}")
        print(f"   Tokens estimados: {total_tokens:,}")
        
        print(f"\nüìã POR TIPO DE CONSULTA:")
        for conv_type, count in type_counts.items():
            percentage = (count / len(conversations)) * 100
            print(f"   {conv_type}: {count} ({percentage:.1f}%)")
        
        print(f"\nüéØ OBJETIVOS DEL ENTRENAMIENTO:")
        print("   ‚Ä¢ Estructura consistente de respuestas")
        print("   ‚Ä¢ Integraci√≥n del contenido real de UCDM")
        print("   ‚Ä¢ Variaci√≥n en lenguaje y ejemplos")
        print("   ‚Ä¢ Aplicaci√≥n pr√°ctica personalizada")
        
        print(f"\nüìù ARCHIVOS GENERADOS:")
        print(f"   ‚Ä¢ ucdm_training_data.jsonl - Dataset principal")
        print(f"   ‚Ä¢ Modelfile_with_training - Configuraci√≥n")
        print(f"   ‚Ä¢ train_model.py - Script de entrenamiento")

def main():
    """Funci√≥n principal"""
    generator = OllamaFineTuningDatasetGenerator()
    
    if generator.generate_complete_training_setup():
        print("\n‚úÖ SETUP DE ENTRENAMIENTO COMPLETADO")
        print("\nüöÄ PASOS SIGUIENTES:")
        print("1. Ejecuta: python ollama/train_model.py")
        print("2. Espera a que complete el entrenamiento")
        print("3. Prueba: ollama run ucdm-gemma-trained")
        return 0
    else:
        print("\n‚ùå ERROR EN SETUP DE ENTRENAMIENTO")
        return 1

if __name__ == "__main__":
    exit(main())