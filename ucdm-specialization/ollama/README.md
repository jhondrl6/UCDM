# üåü Configuraci√≥n de Ollama para UCDM

Esta gu√≠a te ayudar√° a configurar Ollama con el modelo especializado de Un Curso de Milagros.

## üìã Requisitos Previos

1. **Ollama instalado** - Descarga desde [ollama.ai](https://ollama.ai)
2. **Python 3.8+** con las dependencias del proyecto
3. **Al menos 8GB de RAM** para el modelo Gemma 3B
4. **Datos de UCDM extra√≠dos** (ejecutar primero los scripts de extracci√≥n)

## üöÄ Instalaci√≥n Paso a Paso

### 1. Instalar Ollama

**Windows:**
```bash
# Descargar desde https://ollama.ai/download/windows
# Ejecutar el instalador OllamaSetup.exe
```

**macOS:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. Verificar Instalaci√≥n

```bash
ollama version
ollama list  # Debe mostrar lista vac√≠a inicialmente
```

### 3. Configurar Modelo UCDM

```bash
# Desde el directorio del proyecto
cd c:\Users\Jhond\Github\UCDM\ucdm-specialization

# Ejecutar configuraci√≥n autom√°tica
python ollama\setup_model.py
```

El script autom√°ticamente:
- ‚úì Verifica que Ollama est√© funcionando
- ‚úì Descarga el modelo base Gemma 3B (si no existe)
- ‚úì Crea el modelo especializado UCDM
- ‚úì Prueba la funcionalidad
- ‚úì Genera scripts de uso

## üéØ Opciones de Configuraci√≥n

### Opci√≥n 1: Modelo B√°sico (R√°pido)
```bash
python ollama\setup_model.py
```
Crea modelo con prompt system optimizado para UCDM.

### Opci√≥n 2: Modelo con Fine-tuning (Avanzado)
```bash
# Generar datos de entrenamiento
python ollama\generate_training_data.py

# Entrenar modelo personalizado
python ollama\train_model.py
```
Crea modelo entrenado con ejemplos espec√≠ficos de UCDM.

## üíª Formas de Usar el Modelo

### 1. L√≠nea de Comandos Directa
```bash
# Modo interactivo
ollama run ucdm-gemma

# Consulta directa
ollama run ucdm-gemma "Expl√≠came la Lecci√≥n 1"
```

### 2. Script Python
```bash
python ollama\query_ucdm.py "¬øCu√°l es la lecci√≥n de hoy?"
```

### 3. CLI Interactiva del Proyecto
```bash
python ucdm_cli.py
```

### 4. Integraci√≥n con API
```python
import requests

response = requests.post('http://localhost:11434/api/generate', json={
    'model': 'ucdm-gemma',
    'prompt': 'H√°blame sobre el perd√≥n en UCDM',
    'stream': False
})

print(response.json()['response'])
```

## üõ†Ô∏è Configuraci√≥n Avanzada

### Par√°metros del Modelo

El modelo viene preconfigurado con:

```
PARAMETER temperature 0.7      # Creatividad moderada
PARAMETER top_p 0.9           # Diversidad de respuestas
PARAMETER top_k 40            # Variedad de tokens
PARAMETER num_ctx 8192        # Contexto largo
PARAMETER num_predict 2048    # Respuestas detalladas
PARAMETER repeat_penalty 1.1  # Evita repetici√≥n
```

### Personalizar Configuraci√≥n

Edita `ollama/Modelfile` para ajustar:

```dockerfile
# Cambiar temperatura para respuestas m√°s creativas/conservadoras
PARAMETER temperature 0.8

# Ajustar longitud de respuestas
PARAMETER num_predict 1024

# Modificar el prompt del sistema
SYSTEM """Tu prompt personalizado aqu√≠..."""
```

Luego recrea el modelo:
```bash
ollama create ucdm-gemma-custom -f ollama/Modelfile
```

## üß™ Ejemplos de Uso

### Consultas de Lecciones
```bash
ollama run ucdm-gemma "Expl√≠came la Lecci√≥n 15"
ollama run ucdm-gemma "¬øCu√°l es la lecci√≥n de hoy?"
```

### Conceptos del Curso
```bash
ollama run ucdm-gemma "H√°blame sobre el perd√≥n en UCDM"
ollama run ucdm-gemma "¬øQu√© significa 'milagro' seg√∫n el Curso?"
```

### Aplicaci√≥n Pr√°ctica
```bash
ollama run ucdm-gemma "¬øC√≥mo puedo aplicar UCDM cuando tengo miedo?"
ollama run ucdm-gemma "Dame una reflexi√≥n nocturna del Curso"
```

### Respuesta Esperada

Todas las respuestas siguen esta estructura:

```
üéØ HOOK INICIAL: UNA PREGUNTA O AN√âCDOTA PARA ENGANCHAR
[Pregunta profunda que conecta emocionalmente]

‚ö° APLICACI√ìN PR√ÅCTICA: PASOS VIVOS Y VARIADOS
Paso 1: [Acci√≥n concreta con ejemplo]
Paso 2: [Aplicaci√≥n intermedia]
Paso 3: [Integraci√≥n avanzada]

üåø INTEGRACI√ìN EXPERIENCIAL: CONEXI√ìN VIVA Y REFLEXIVA
[Conexi√≥n personal y preguntas reflexivas]

‚ú® CIERRE MOTIVADOR: UN MILAGRO FINAL
[Invitaci√≥n inspiradora a la acci√≥n]
```

## üîß Soluci√≥n de Problemas

### Error: "Ollama not found"
```bash
# Verificar instalaci√≥n
which ollama  # Linux/macOS
where ollama  # Windows

# Reiniciar servicio
ollama serve
```

### Error: "Model not found"
```bash
# Listar modelos disponibles
ollama list

# Recrear modelo
python ollama\setup_model.py
```

### Error: "Out of memory"
```bash
# Verificar RAM disponible
ollama ps

# Usar modelo m√°s peque√±o
ollama pull gemma:2b
# Editar Modelfile: FROM gemma:2b
```

### Respuestas Inconsistentes
```bash
# Regenerar con fine-tuning
python ollama\generate_training_data.py
python ollama\train_model.py
```

## üìä Monitoreo del Modelo

### Verificar Estado
```bash
ollama ps  # Modelos en ejecuci√≥n
ollama list  # Modelos instalados
```

### Estad√≠sticas de Uso
```bash
# Ver logs
ollama logs

# Rendimiento
time ollama run ucdm-gemma "test query"
```

## üîÑ Actualizaciones

### Actualizar Datos del Curso
```bash
# Re-extraer PDF si hay nueva versi√≥n
python extraction\pdf_extractor.py

# Regenerar √≠ndices
python extraction\lesson_indexer.py

# Recrear modelo
python ollama\setup_model.py
```

### Actualizar Ollama
```bash
# Backup modelo actual
ollama cp ucdm-gemma ucdm-gemma-backup

# Actualizar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar compatibilidad
python ollama\setup_model.py
```

## üéØ Mejores Pr√°cticas

### Para Usuarios Diarios
1. **Usa CLI interactiva**: `python ucdm_cli.py`
2. **Consulta lecci√≥n del d√≠a**: `ollama run ucdm-gemma "¬ølecci√≥n de hoy?"`
3. **Reflexiones nocturnas**: `ollama run ucdm-gemma "reflexi√≥n nocturna"`

### Para Desarrolladores
1. **API REST**: Integra con `http://localhost:11434/api`
2. **Fine-tuning**: Usa `generate_training_data.py`
3. **Monitoring**: Implementa logs de consultas

### Para Estudiantes del Curso
1. **Consultas regulares**: Establece rutina diaria
2. **Profundizaci√≥n**: Explora conceptos espec√≠ficos
3. **Aplicaci√≥n pr√°ctica**: Usa ejemplos cotidianos

## üìû Soporte

Si encuentras problemas:

1. **Revisa logs**: `ollama logs`
2. **Verifica recursos**: RAM, espacio en disco
3. **Consulta documentaci√≥n**: [ollama.ai/docs](https://ollama.ai/docs)
4. **Regenera modelo**: `python ollama\setup_model.py`

---

üåü **¬°Disfruta explorando Un Curso de Milagros con tu asistente especializado!** üåü